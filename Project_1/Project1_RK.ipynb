{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0825fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73421eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "filename = \"Project_1_dataset_01_01_2022.csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5358dd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>keywords</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>url</th>\n",
       "      <th>leaf_label</th>\n",
       "      <th>root_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590</td>\n",
       "      <td>Having made a massive impact in Saudi Arabia w...</td>\n",
       "      <td>Having made a massive impact in Saudi Arabia w...</td>\n",
       "      <td>['singhs', 'rooting', 'cool', 'saudi', 'style'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.msn.com/en-in/entertainment/other/...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>388</td>\n",
       "      <td>Cricket is all about the emotional rollercoast...</td>\n",
       "      <td>No matter which team fans hope to win, every s...</td>\n",
       "      <td>['wants', 'fans', 'finals', 'cup', 'win', 'tou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.prnewswire.com:443/news-releases/c...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423</td>\n",
       "      <td>New Zealand announces back-to-back tours next ...</td>\n",
       "      <td>New Zealand announces back-to-back tours next ...</td>\n",
       "      <td>['test', 'west', 'tour', 'zealand', 'world', '...</td>\n",
       "      <td>2021-12-20 00:00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.aljazeera.com/news/2021/12/20/cric...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>563</td>\n",
       "      <td>It's not the first time cricket fans in the co...</td>\n",
       "      <td>Billed as one of the pre-tournament favourites...</td>\n",
       "      <td>['qualify', 'afghanistan', 'cup', 'world', 'ze...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.msn.com/en-in/news/other/t20-world...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>634</td>\n",
       "      <td>An employee works on a computer terminal again...</td>\n",
       "      <td>REUTERS/Sivaram VBENGALURU, Oct 11 (Reuters Br...</td>\n",
       "      <td>['success', 'tech', 'startup', 'talent', 'onli...</td>\n",
       "      <td>2021-10-11 00:00:00</td>\n",
       "      <td>['Una Galani']</td>\n",
       "      <td>https://www.reuters.com/breakingviews/india-in...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          full_text  \\\n",
       "0         590  Having made a massive impact in Saudi Arabia w...   \n",
       "1         388  Cricket is all about the emotional rollercoast...   \n",
       "2         423  New Zealand announces back-to-back tours next ...   \n",
       "3         563  It's not the first time cricket fans in the co...   \n",
       "4         634  An employee works on a computer terminal again...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Having made a massive impact in Saudi Arabia w...   \n",
       "1  No matter which team fans hope to win, every s...   \n",
       "2  New Zealand announces back-to-back tours next ...   \n",
       "3  Billed as one of the pre-tournament favourites...   \n",
       "4  REUTERS/Sivaram VBENGALURU, Oct 11 (Reuters Br...   \n",
       "\n",
       "                                            keywords         publish_date  \\\n",
       "0  ['singhs', 'rooting', 'cool', 'saudi', 'style'...                  NaN   \n",
       "1  ['wants', 'fans', 'finals', 'cup', 'win', 'tou...                  NaN   \n",
       "2  ['test', 'west', 'tour', 'zealand', 'world', '...  2021-12-20 00:00:00   \n",
       "3  ['qualify', 'afghanistan', 'cup', 'world', 'ze...                  NaN   \n",
       "4  ['success', 'tech', 'startup', 'talent', 'onli...  2021-10-11 00:00:00   \n",
       "\n",
       "          authors                                                url  \\\n",
       "0              []  https://www.msn.com/en-in/entertainment/other/...   \n",
       "1              []  https://www.prnewswire.com:443/news-releases/c...   \n",
       "2              []  https://www.aljazeera.com/news/2021/12/20/cric...   \n",
       "3              []  https://www.msn.com/en-in/news/other/t20-world...   \n",
       "4  ['Una Galani']  https://www.reuters.com/breakingviews/india-in...   \n",
       "\n",
       "  leaf_label root_label  \n",
       "0    cricket     sports  \n",
       "1    cricket     sports  \n",
       "2    cricket     sports  \n",
       "3    cricket     sports  \n",
       "4    cricket     sports  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c97eb2",
   "metadata": {},
   "source": [
    "## Question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2fa27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27657523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column count which stores length of alpha numeric characters\n",
    "df['count'] =  df['full_text'].apply(lambda x: sum(char.isalnum() for char in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f52c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# histogram: alpha-numeric characters in document\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(df['count'],50)\n",
    "plt.xlabel('char_count')\n",
    "plt.ylabel('frequency')\n",
    "plt.title(\"Frequency plot : alpha-numeric characters\")\n",
    "# plt.show()\n",
    "plt.savefig('plot_1.png')\n",
    "df = df.drop('count',axis=1)   ## drop new column count after creating the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5794aabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram: leaf_label\n",
    "leaf_label_counts = pd.DataFrame(df['leaf_label'].value_counts()).reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(leaf_label_counts['index'],leaf_label_counts['leaf_label'] ,0.5)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('frequency')\n",
    "plt.title(\"Frequency plot : leaf_label\")\n",
    "plt.savefig('plot_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474b84a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram: root_label\n",
    "root_label_counts = pd.DataFrame(df['root_label'].value_counts()).reset_index()\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.bar(root_label_counts['index'],root_label_counts['root_label'] ,0.5)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('frequency')\n",
    "plt.title(\"Frequency plot : root_label\")\n",
    "plt.savefig('plot_3.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af0b03a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number:2072\n",
      "column number:9\n"
     ]
    }
   ],
   "source": [
    "print(\"sample number:{}\".format(df.shape[0]))\n",
    "print(\"column number:{}\".format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2413fc7",
   "metadata": {},
   "source": [
    "## Question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fdb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd078da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train number:1657\n",
      "test number:415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def question2(train,test):\n",
    "    \n",
    "    train_num = train.shape[0]\n",
    "    test_num = test.shape[0]\n",
    "    return train_num,test_num\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state = 42)\n",
    "\n",
    "train_num,test_num = question2(train,test)\n",
    "print(\"train number:{}\".format(train_num))\n",
    "print(\"test number:{}\".format(test_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828a51a",
   "metadata": {},
   "source": [
    "## Question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea659823",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import re\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords' )\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "stop_words_skt = text.ENGLISH_STOP_WORDS\n",
    "stop_words_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5d4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    '''\n",
    "    Helps remove many HTML artefacts from the crawler's output.\n",
    "    '''\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter\n",
    "\n",
    "def clean_data(data):\n",
    "    for index,row in data.iterrows():\n",
    "        row['full_text'] = clean(row['full_text'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d2f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### IMP: still need to determine the right order of cleaning steps\n",
    "# ## Right now the order is --> clean html, remove_punctuation, lemmatize, remove digit, stopwords and chars\n",
    "\n",
    "# ## Building 6 analyzers for [clean, no clean]*[lemmatize, stem, no compression] combinations\n",
    "\n",
    "\n",
    "# combined_stopwords = set.union(set(stop_words_en),set(punctuation),set(stop_words_skt))\n",
    "# wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "# stemmer = nltk.stem.PorterStemmer()\n",
    "# analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "# def penn2morphy(penntag):\n",
    "#     \"\"\" \n",
    "#     Converts Penn Treebank tags to WordNet. \n",
    "#     \"\"\"\n",
    "#     morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "#                   'VB':'v', 'RB':'r'}\n",
    "#     try:\n",
    "#         return morphy_tag[penntag[:2]]\n",
    "#     except:\n",
    "#         return 'n' \n",
    "\n",
    "# def lemmatize_sent(list_word): \n",
    "#     '''\n",
    "#     Returns lemmatized set of tokens with pos tagging\n",
    "#     '''\n",
    "#     return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "#             for word, tag in pos_tag(list_word)]\n",
    "\n",
    "# def clean_tokens_lemma (tokens: list):\n",
    "#     '''\n",
    "#     Cleans set of tokens at sentence level by applying lemmatization at sentence level\n",
    "#     '''\n",
    "#     lower_txt = [token.lower() for token in tokens]\n",
    "#     lemmatize_tokens = lemmatize_sent(lower_txt) \n",
    "#     remove_words = [token for token in lemmatize_tokens if (not token.isdigit())\\\n",
    "#                      and (token not in combined_stopwords) and (len(token)>1)]\n",
    "#     return remove_words\n",
    "\n",
    "# def doc_tokens_lemma (doc):\n",
    "#     '''\n",
    "#     Split the document at sentence level, clean it and return clean set of tokens at doc level\n",
    "#     '''\n",
    "#     doc = clean(doc)\n",
    "#     list_sentences = sent_tokenize(doc)\n",
    "#     doc_tokens = []\n",
    "#     for sentence in list_sentences:\n",
    "#         sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "#         tokens = nltk.word_tokenize(sentence)\n",
    "#         tokens = clean_tokens_lemma(tokens)\n",
    "#         doc_tokens.extend(tokens)\n",
    "# #     print(doc_tokens)\n",
    "#     return (word for word in doc_tokens)     \n",
    "\n",
    "# def doc_tokens_lemma_woClean (doc):\n",
    "#     '''\n",
    "#     Perform lemmatization without any text cleaning\n",
    "#     '''\n",
    "#     list_sentences = sent_tokenize(doc)\n",
    "#     doc_tokens = []\n",
    "#     for sentence in list_sentences:\n",
    "#         tokens = nltk.word_tokenize(sentence)\n",
    "#         tokens = lemmatize_sent(tokens)\n",
    "#         doc_tokens.extend(tokens)\n",
    "# #     print(doc_tokens)\n",
    "#     return (word for word in doc_tokens)   \n",
    "\n",
    "# def doc_tokens_stem (doc):\n",
    "#     '''\n",
    "#     Clean full text using stemming. This function does not require split at sentence level.\n",
    "#     '''\n",
    "#     doc = clean(doc)\n",
    "#     doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "#     tokens = nltk.word_tokenize(doc)\n",
    "#     lower_txt = [token.lower() for token in tokens]\n",
    "#     stem_tokens = [stemmer.stem(token) for token in lower_txt] \n",
    "#     remove_words = [token for token in stem_tokens if (not token.isdigit())\\\n",
    "#                      and (token not in combined_stopwords) and (len(token)>1)]\n",
    "#     return (word for word in remove_words)\n",
    "\n",
    "# def doc_tokens_stem_woClean (doc):\n",
    "#     '''\n",
    "#     Clean full text using stemming. This function does not require split at sentence level.\n",
    "#     '''\n",
    "#     tokens = nltk.word_tokenize(doc)\n",
    "#     lower_txt = [token.lower() for token in tokens]\n",
    "#     stem_tokens = [stemmer.stem(token) for token in lower_txt] \n",
    "#     return (word for word in stem_tokens)\n",
    "    \n",
    "# def doc_tokens (doc):\n",
    "#     '''\n",
    "#     Clean full text without any stemming or lemmatization\n",
    "#     '''\n",
    "#     doc = clean(doc)\n",
    "#     doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "#     tokens = nltk.word_tokenize(doc)\n",
    "#     lower_txt = [token.lower() for token in tokens]\n",
    "#     remove_words = [token for token in lower_txt if (not token.isdigit())\\\n",
    "#                      and (token not in combined_stopwords) and (len(token)>1)]\n",
    "#     return (word for word in remove_words)\n",
    "    \n",
    "# def doc_tokens_woClean (doc):\n",
    "#     '''\n",
    "#     Clean full text using stemming. This function does not require split at sentence level.\n",
    "#     '''\n",
    "#     tokens = nltk.word_tokenize(doc)\n",
    "#     lower_txt = [token.lower() for token in tokens]\n",
    "#     return (word for word in lower_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26327f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMP: still need to determine the right order of cleaning steps\n",
    "## Right now the order is --> clean html, remove_punctuation, lemmatize, remove digit, stopwords and chars\n",
    "\n",
    "## Building 6 analyzers for [clean, no clean]*[lemmatize, stem, no compression] combinations\n",
    "\n",
    "\n",
    "combined_stopwords = set.union(set(stop_words_en),set(punctuation),set(stop_words_skt))\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" \n",
    "    Converts Penn Treebank tags to WordNet. \n",
    "    \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "\n",
    "def lemmatize_sent(list_word): \n",
    "    '''\n",
    "    Returns lemmatized set of tokens with pos tagging\n",
    "    '''\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]\n",
    "\n",
    "def clean_tokens_lemma (tokens: list):\n",
    "    '''\n",
    "    Cleans set of tokens at sentence level by applying lemmatization at sentence level\n",
    "    '''\n",
    "    lower_txt = [token.lower() for token in tokens]\n",
    "    remove_words = [token for token in lower_txt if (not token.isdigit())\\\n",
    "                     and (token not in combined_stopwords) and (len(token)>1)]\n",
    "    lemmatize_tokens = lemmatize_sent(remove_words) \n",
    "    return lemmatize_tokens\n",
    "\n",
    "def doc_tokens_lemma (doc):\n",
    "    '''\n",
    "    Split the document at sentence level, clean it and return clean set of tokens at doc level\n",
    "    '''\n",
    "    doc = clean(doc)\n",
    "    list_sentences = sent_tokenize(doc)\n",
    "    doc_tokens = []\n",
    "    for sentence in list_sentences:\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        tokens = clean_tokens_lemma(tokens)\n",
    "        doc_tokens.extend(tokens)\n",
    "#     print(doc_tokens)\n",
    "    return (word for word in doc_tokens)     \n",
    "\n",
    "def doc_tokens_lemma_woClean (doc):\n",
    "    '''\n",
    "    Perform lemmatization without any text cleaning\n",
    "    '''\n",
    "    list_sentences = sent_tokenize(doc)\n",
    "    doc_tokens = []\n",
    "    for sentence in list_sentences:\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        tokens = lemmatize_sent(tokens)\n",
    "        doc_tokens.extend(tokens)\n",
    "#     print(doc_tokens)\n",
    "    return (word for word in doc_tokens)   \n",
    "\n",
    "def doc_tokens_stem (doc):\n",
    "    '''\n",
    "    Clean full text using stemming. This function does not require split at sentence level.\n",
    "    '''\n",
    "    doc = clean(doc)\n",
    "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    lower_txt = [token.lower() for token in tokens]\n",
    "    remove_words = [token for token in lower_txt if (not token.isdigit())\\\n",
    "                     and (token not in combined_stopwords) and (len(token)>1)]\n",
    "    stem_tokens = [stemmer.stem(token) for token in remove_words] \n",
    "    return (word for word in stem_tokens)\n",
    "\n",
    "def doc_tokens_stem_woClean (doc):\n",
    "    '''\n",
    "    Clean full text using stemming. This function does not require split at sentence level.\n",
    "    '''\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    lower_txt = [token.lower() for token in tokens]\n",
    "    stem_tokens = [stemmer.stem(token) for token in lower_txt] \n",
    "    return (word for word in stem_tokens)\n",
    "    \n",
    "def doc_tokens (doc):\n",
    "    '''\n",
    "    Clean full text without any stemming or lemmatization\n",
    "    '''\n",
    "    doc = clean(doc)\n",
    "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    lower_txt = [token.lower() for token in tokens]\n",
    "    remove_words = [token for token in lower_txt if (not token.isdigit())\\\n",
    "                     and (token not in combined_stopwords) and (len(token)>1)]\n",
    "    return (word for word in remove_words)\n",
    "    \n",
    "def doc_tokens_woClean (doc):\n",
    "    '''\n",
    "    Clean full text using stemming. This function does not require split at sentence level.\n",
    "    '''\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    lower_txt = [token.lower() for token in tokens]\n",
    "    return (word for word in lower_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3288f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stemming vs lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412782c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_lemma = CountVectorizer(min_df=3, stop_words='english', analyzer=doc_tokens_lemma, max_df=0.7)\n",
    "X_train_counts = count_vectorizer_lemma.fit_transform(train['full_text'])\n",
    "print(\"Lemmatization dictionary size is: \", X_train_counts.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_stem = CountVectorizer(min_df=3, stop_words='english', analyzer=doc_tokens_stem, max_df=0.7)\n",
    "X_train_counts = count_vectorizer_stem.fit_transform(train['full_text'])\n",
    "print(\"Stemming dictionary size is: \", X_train_counts.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of minimum data frequency on tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dfs = range(1,5)\n",
    "for min_df in min_dfs:\n",
    "    count_vectorizer1 = CountVectorizer(min_df=min_df, stop_words='english', analyzer=doc_tokens_lemma, max_df=0.7)\n",
    "    X_train_counts1 = count_vectorizer1.fit_transform(train['full_text'])\n",
    "    \n",
    "    transformer1 = TfidfTransformer()\n",
    "    X_train_tfidf = transformer1.fit_transform(X_train_counts1)\n",
    "    \n",
    "    print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7caf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dfs = range(1,5)\n",
    "for min_df in min_dfs:\n",
    "    count_vectorizer1 = CountVectorizer(min_df=min_df, stop_words='english', analyzer=doc_tokens_stem, max_df=0.7)\n",
    "    X_train_counts1 = count_vectorizer1.fit_transform(train['full_text'])\n",
    "    \n",
    "    transformer1 = TfidfTransformer()\n",
    "    X_train_tfidf = transformer1.fit_transform(X_train_counts1)\n",
    "    \n",
    "    print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f927f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf-idf processed train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5645652",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=3, stop_words='english', analyzer=doc_tokens_lemma, max_df=0.7)\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "X_train_counts = count_vectorizer.fit_transform(train['full_text'])\n",
    "X_train_tfidf = transformer.fit_transform(X_train_counts)\n",
    "\n",
    "X_test_counts = count_vectorizer.transform(test['full_text'])\n",
    "X_test_tfidf = transformer.transform(X_test_counts)\n",
    "\n",
    "print('TF-IDF processed train data shape:', X_train_tfidf.shape)\n",
    "print('TF-IDF processed test data shape:', X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4900a",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411057c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "# Run LSI for various k values\n",
    "k_list = [1,10,50,100,200,500,1000,2000]\n",
    "explained_ratio = []\n",
    "for k in k_list:\n",
    "    svd = TruncatedSVD(n_components=k, n_iter = 20, random_state=42)\n",
    "    svd.fit(X_train_tfidf)\n",
    "    # print(svd.explained_variance_ratio_.sum())\n",
    "    explained_ratio.append(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "# plotting the explained variance ratio across number of components\n",
    "plt.plot(k_list, explained_ratio)\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_ratio')\n",
    "plt.title('LSI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23521f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_50 = TruncatedSVD(n_components=50, n_iter = 20, random_state=42)\n",
    "X_train_lsi = SVD_50.fit_transform(X_train_tfidf)\n",
    "X_test_lsi = SVD_50.transform(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "NMF_50 = NMF(n_components=50, max_iter = 500, init='random', random_state=42)\n",
    "X_train_nmf = NMF_50.fit_transform(X_train_tfidf)\n",
    "X_test_nmf = NMF_50.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c208895",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT = SVD_50.components_\n",
    "X_train_svd_recons = np.matmul(X_train_lsi, VT)\n",
    "norm_train = ((X_train_tfidf.toarray() - X_train_svd_recons)**2).sum(axis = None)\n",
    "mse_train = ((X_train_tfidf.toarray() - X_train_svd_recons)**2).mean(axis = None)\n",
    "X_test_svd_recons = np.matmul(X_test_lsi, VT)\n",
    "norm_test = ((X_test_tfidf.toarray() - X_test_svd_recons)**2).sum(axis = None)\n",
    "mse_test = ((X_test_tfidf.toarray() - X_test_svd_recons)**2).mean(axis = None)\n",
    "print(mse_train, mse_test, norm_train, norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = NMF_50.components_\n",
    "X_train_nmf_recons = np.matmul(X_train_nmf, H)\n",
    "norm_train = ((X_train_tfidf.toarray() - X_train_nmf_recons)**2).sum(axis = None)\n",
    "mse_train = ((X_train_tfidf.toarray() - X_train_nmf_recons)**2).mean(axis = None)\n",
    "X_test_nmf_recons = np.matmul(X_test_nmf, H)\n",
    "norm_test = ((X_test_tfidf.toarray() - X_test_nmf_recons)**2).sum(axis = None)\n",
    "mse_test = ((X_test_tfidf.toarray() - X_test_nmf_recons)**2).mean(axis = None)\n",
    "print(mse_train, mse_test, norm_train, norm_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4f646",
   "metadata": {},
   "source": [
    "Why?\n",
    "\n",
    "Both NMF and SVD represent a set of vectors in a given basis. The basis in NMF is composed of vectors with positive elements while the basis in SVD can have positive or negative values.\n",
    "\n",
    "The difference then is that NMF reconstructs each vector as a positive summation of the basis vectors, in other words you take a little of each vector in the basis to reconstruct your data.\n",
    "\n",
    "In SVD the data is modeled as a linear combination of the basis you can add or substract vectors as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb5db3",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data pre-processing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "## train model\n",
    "y_train = label_encoder.fit_transform(train['root_label'])\n",
    "y_test = label_encoder.fit_transform(test['root_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9808aefb",
   "metadata": {},
   "source": [
    "### Train SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411678a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train linear SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_hard = SVC(kernel='linear', C=1000, random_state=42)\n",
    "svm_soft = SVC(kernel='linear', C=0.0001, random_state=42)\n",
    "\n",
    "svm_hard.fit(X_train_lsi, y_train)\n",
    "svm_soft.fit(X_train_lsi, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC\n",
    "from sklearn import metrics\n",
    "\n",
    "def plot_ROC(fpr,tpr):\n",
    "    fig = plt.figure()\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "    plt.plot(fpr,tpr,label=\"area under curve = %0.3f\" %roc_auc)\n",
    "    plt.xlabel('False positive rate',fontsize=10)\n",
    "    plt.ylabel('True positive rate',fontsize=10)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.savefig('plot.png')\n",
    "    return roc_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for svm_hard\n",
    "score_hard = svm_hard.decision_function(X_test_lsi)\n",
    "fpr_hard,tpr_hard,_ = metrics.roc_curve(y_test,score_hard)\n",
    "auc_hard = plot_ROC(fpr_hard,tpr_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for svm_hard\n",
    "score_soft = svm_soft.decision_function(X_test_lsi)\n",
    "fpr_soft,tpr_soft,_ = metrics.roc_curve(y_test,score_soft)\n",
    "auc_soft = plot_ROC(fpr_soft,tpr_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32232673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison\n",
    "if auc_hard > auc_soft:\n",
    "    print('SVM_hard is better')\n",
    "else:\n",
    "    print('SVM_soft is better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a040843",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_veryHard = SVC(kernel='linear', C=100000, random_state=42)\n",
    "svm_veryHard.fit(X_train_lsi, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for svm_veryHard\n",
    "score_veryHard = svm_veryHard.decision_function(X_test_lsi)\n",
    "fpr_veryHard,tpr_veryHard,_ = metrics.roc_curve(y_test,score_veryHard)\n",
    "auc_veryHard = plot_ROC(fpr_veryHard,tpr_veryHard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(classifier,test_data,y_test):\n",
    "    y_test_pred = classifier.predict(test_data)\n",
    "    print('-'*20)\n",
    "    print(\"Confusion matrix on test set is: \")\n",
    "    print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "    print('-'*20)\n",
    "    print('-'*20)\n",
    "    print(\"Performance metrics on test set is: \")\n",
    "    print (\"Precision is: \", metrics.precision_score(y_test, y_test_pred))\n",
    "    print (\"Recall is: \", metrics.recall_score(y_test, y_test_pred))\n",
    "    print (\"Accuracy is: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "    print (\"F1 score is: \", metrics.f1_score(y_test, y_test_pred))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance of SVM hard\")\n",
    "print('_' * 40)\n",
    "evaluation(svm_hard,X_test_lsi,y_test)\n",
    "print('_' * 60)\n",
    "print(\"Performance of SVM soft\")\n",
    "print('_' * 40)\n",
    "evaluation(svm_soft,X_test_lsi,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150141b0",
   "metadata": {},
   "source": [
    "### Use cross-validation to choose $\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f092fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate(classifier, train, label):\n",
    "    avg_score = []\n",
    "\n",
    "    for k in range(-3, 7):\n",
    "        classifier.set_params(C=10**k).fit(train, label)\n",
    "        cv = KFold(n_splits=5, random_state=42,shuffle=True)\n",
    "        scores = cross_val_score(classifier, train, label, cv=cv, scoring='accuracy', n_jobs = -1)\n",
    "    \n",
    "        print('-'*20,'C =',10**k,'-'*20)\n",
    "        print(scores)\n",
    "        print(np.average(scores))\n",
    "        avg_score.append(np.average(scores))\n",
    "\n",
    "    max_score = np.max(avg_score)\n",
    "    index = avg_score.index(max_score)\n",
    "    c_idx = [x for x in range(-3,4)][index]\n",
    "    print('-'*20,'Result','-'*20)\n",
    "    print('The best classifier is when C =', 10**c_idx)\n",
    "    print('Average Accuracy is:', max_score)\n",
    "    \n",
    "    return classifier.set_params(C=10**c_idx).fit(train,label)\n",
    "\n",
    "svm_best = cross_validate(SVC(kernel='linear', random_state=42), X_train_lsi, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc0d7b",
   "metadata": {},
   "source": [
    "##### The best $\\gamma$ for SVM is c = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for svm_best\n",
    "svm_best_train = SVC(kernel='linear', C=10, random_state=42)\n",
    "svm_best_train.fit(X_train_lsi, y_train)\n",
    "score_best = svm_best.decision_function(X_test_lsi)\n",
    "fpr_best,tpr_best,_ = metrics.roc_curve(y_test,score_best)\n",
    "auc_best = plot_ROC(fpr_soft,tpr_soft)\n",
    "print(\"auc_best:%0.4f\" % auc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate this svm_best model\n",
    "print(\"Performance of SVM soft\")\n",
    "print('_' * 40)\n",
    "evaluation(svm_best,X_test_lsi,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c82b9",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logistic = LogisticRegression(penalty = 'none',solver = 'saga', max_iter=10000)\n",
    "logistic.fit(X_train_lsi, y_train)\n",
    "\n",
    "\n",
    "y_test_pred = logistic.predict(X_test_lsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for logistic regression\n",
    "y_test_pred_prob = logistic.predict_proba(X_test_lsi)[::,1]\n",
    "fpr_best,tpr_best,_ = metrics.roc_curve(y_test,y_test_pred_prob)\n",
    "auc_best = plot_ROC(fpr_soft,tpr_soft)\n",
    "print(\"auc_best:%0.4f\" % auc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance of Logistic regression without regularisation\")\n",
    "print('_' * 40)\n",
    "evaluation(logistic,X_test_lsi,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420187e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find optimal regularisation strength for L1 and L2 regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_logistic(classifier, train, label):\n",
    "    avg_score = []\n",
    "\n",
    "    for k in range(-4, 5):\n",
    "        classifier.set_params(C=10**k).fit(train, label)\n",
    "        cv = KFold(n_splits=5, random_state=42,shuffle=True)\n",
    "        scores = cross_val_score(classifier, train, label, cv=cv, scoring='accuracy', n_jobs = -1)\n",
    "    \n",
    "        print('-'*20,'C =',10**k,'-'*20)\n",
    "        print(scores)\n",
    "        print(np.average(scores))\n",
    "        avg_score.append(np.average(scores))\n",
    "\n",
    "    max_score = np.max(avg_score)\n",
    "    index = avg_score.index(max_score)\n",
    "    c_idx = [x for x in range(-3,4)][index]\n",
    "    print('-'*20,'Result','-'*20)\n",
    "    print('The best classifier is when C =', 10**c_idx)\n",
    "    print('Average Accuracy is:', max_score)\n",
    "    \n",
    "    return classifier.set_params(C=10**c_idx).fit(train,label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042edbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticL1_best = cross_validate_logistic(LogisticRegression(penalty = 'l1', solver='saga', max_iter=10000), X_train_lsi, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1584d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticL2_best = cross_validate_logistic(LogisticRegression(penalty = 'l2', solver='saga', max_iter=10000), X_train_lsi, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal regularisation strength for Logistic \\\n",
    "regression with L1 regularisation is 100')\n",
    "print('Optimal regularisation strength for Logistic \\\n",
    "regression with L2 regularisation is 1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on entire train dataset\n",
    "logisticL1 = LogisticRegression(penalty = 'l1', solver='saga', max_iter=10000, C=100)\n",
    "logisticL2 = LogisticRegression(penalty = 'l2', solver='saga', max_iter=10000, C=1000)\n",
    "logisticL1.fit(X_train_lsi,y_train)\n",
    "logisticL2.fit(X_train_lsi,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaedf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance of Logistic w/o regularisation is: \")\n",
    "print('_' * 40)\n",
    "evaluation(logistic,X_test_lsi,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance of Logistic w L1 regularisation is: \")\n",
    "print('_' * 40)\n",
    "evaluation(logisticL1,X_test_lsi,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e25aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance of Logistic w L2 regularisation is: \")\n",
    "print('_' * 40)\n",
    "evaluation(logisticL2,X_test_lsi,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab3e99",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c02fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "naivebayes = GaussianNB()\n",
    "naivebayes.fit(X_train_lsi, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for logistic regression\n",
    "y_test_pred_prob = naivebayes.predict_proba(X_test_lsi)[::,1]\n",
    "fpr_best,tpr_best,_ = metrics.roc_curve(y_test,y_test_pred_prob)\n",
    "auc_best = plot_ROC(fpr_soft,tpr_soft)\n",
    "print(\"auc_best:%0.4f\" % auc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance of Naive Bayes classification\")\n",
    "print('_' * 40)\n",
    "evaluation(naivebayes,X_test_lsi,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8762ae",
   "metadata": {},
   "source": [
    "## Question 8: Comparison between three classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d884ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3, analyzer=doc_tokens_lemma)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(n_components=50, random_state=42)),\n",
    "    ('clf', SVC(kernel='linear', C=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(train.full_text, x_test)\n",
    "predict = pipeline.predict(test.full_text)\n",
    "print(\"accuracy:{}\".format(metrics.accuracy_score(y_test, predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6860375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# used to cache results\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848bd3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = joblib.Memory(location=cachedir, verbose=10)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=1, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(random_state=42)),\n",
    "    ('clf', GaussianNB()),\n",
    "],\n",
    "memory=memory\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'vect': [\n",
    "            CountVectorizer(min_df=3, analyzer=doc_tokens_lemma),   ## lemmatization with data cleaning\n",
    "            CountVectorizer(min_df=3, analyzer=doc_tokens_stem),    ## stemming with data cleaning\n",
    "            CountVectorizer(min_df=3, analyzer=doc_tokens),   ## no compression with data cleaning\n",
    "            CountVectorizer(min_df=3, analyzer=doc_tokens_lemma_woClean), ## lemmatization without data cleaning\n",
    "            CountVectorizer(min_df=3, analyzer=doc_tokens_stem_woClean), ## stemming without data cleaning\n",
    "            CountVectorizer(min_df=3, analyzer=doc_tokens_woClean),  ## no compression with data cleaning\n",
    "            CountVectorizer(min_df=5, analyzer=doc_tokens_lemma),   \n",
    "            CountVectorizer(min_df=5, analyzer=doc_tokens_stem),    \n",
    "            CountVectorizer(min_df=5, analyzer=doc_tokens),   \n",
    "            CountVectorizer(min_df=5, analyzer=doc_tokens_lemma_woClean), \n",
    "            CountVectorizer(min_df=5, analyzer=doc_tokens_stem_woClean), \n",
    "            CountVectorizer(min_df=5, analyzer=doc_tokens_woClean)\n",
    "        ],\n",
    "        'reduce_dim': [TruncatedSVD(n_components=5, n_iter=20, random_state=42),\n",
    "                       TruncatedSVD(n_components=50, n_iter=20, random_state=42),\n",
    "                       TruncatedSVD(n_components=500, n_iter=20, random_state=42),\n",
    "                       NMF(n_components=5, max_iter=500, init='random', random_state=42),\n",
    "                       NMF(n_components=50, max_iter=500, init='random', random_state=42),\n",
    "                       NMF(n_components=500, max_iter=500, init='random', random_state=42)\n",
    "        ],\n",
    "        'clf': [SVC(kernel='linear', C=10, random_state=42),\n",
    "                LogisticRegression(penalty='l1', C=100, random_state=42),\n",
    "                LogisticRegression(penalty='l2', C=1000, random_state=42),\n",
    "                GaussianNB()\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccaa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search no clean data\n",
    "grid = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=param_grid, scoring='accuracy')\n",
    "grid.fit(train.full_text, train_label)\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = pd.DataFrame(grid.cv_results_)\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e99e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.save(\"results\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b22feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_list = {}\n",
    "k = 1\n",
    "for i,row in enumerate(result['rank_test_score']):\n",
    "    if row >= 1 and row <= 5:\n",
    "        best_list[row] = i\n",
    "    \n",
    "print(\"The index of 5 best combination:{}\".format(best_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859deca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while i <= 5:\n",
    "    index = best_list[i]\n",
    "    print(\"_\" * 80)\n",
    "    print(\"rank_test_score:\")\n",
    "    print(result['rank_test_score'][index]) \n",
    "    print(\"_\" * 20)\n",
    "    print(\"mean_test_score:\")\n",
    "    print(result['mean_test_score'][index])     \n",
    "    print(\"_\" * 20)\n",
    "    print(\"model parameters:\")\n",
    "    print(result['params'][index])  \n",
    "    print(\"_\" * 80)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report their performance on the testing set \n",
    "pipeline1 = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=5, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(n_components=500, random_state=42)),\n",
    "    ('clf', LogisticRegression(C=10, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline1.fit(train.full_text, train_label)\n",
    "predict = pipeline1.predict(test.full_text)\n",
    "\n",
    "print(classification_report(test_label, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874788ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrain the above 5 best models on trainset and report on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c2a3d",
   "metadata": {},
   "source": [
    "## Question 9: Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538603b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_row_to_class = {0:\"chess\", 1:\"cricket\", 2:\"soccer\", 3:\"football\", \\\n",
    "                    4:\"%22forest%20fire%22\", 5:\"flood\", 6:\"earthquake\", 7:\"drought\"}\n",
    "\n",
    "map_class_to_val = {\"chess\": 0, \"cricket\": 1, \"soccer\": 2, \"football\": 3, \\\n",
    "                    \"%22forest%20fire%22\": 4, \"flood\": 5, \"earthquake\": 6, \"drought\": 7}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive bayes classification\n",
    "\n",
    "k = 50\n",
    "\n",
    "## train the model\n",
    "\n",
    "## define model\n",
    "count_vectorizer = CountVectorizer(min_df=3, stop_words='english', analyzer=doc_tokens_lemma, max_df=0.7)\n",
    "transformer = TfidfTransformer()\n",
    "nmf = NMF(n_components=k, max_iter=500, init='random', random_state=42)  ## Multinomial NB can take only positive values\n",
    "svd = TruncatedSVD(n_components=k, n_iter=20, random_state=42) \n",
    "clf = MultinomialNB()\n",
    "\n",
    "## train model\n",
    "train['leaf_label_encode']= train['leaf_label'].map(map_class_to_val)\n",
    "\n",
    "y_train = train['leaf_label_encode']\n",
    "# print(y_train)\n",
    "X_train_counts = count_vectorizer.fit_transform(train['full_text'])\n",
    "X_train_tfidf = transformer.fit_transform(X_train_counts)\n",
    "X_train_nmf = nmf.fit_transform(X_train_tfidf)\n",
    "model = clf.fit(X_train_nmf, y_train)\n",
    "\n",
    "## get train parameters\n",
    "\n",
    "## test model\n",
    "test['leaf_label_encode']= test['leaf_label'].map(map_class_to_val)\n",
    "\n",
    "y_test = test['leaf_label_encode']\n",
    "X_test_counts = count_vectorizer.transform(test['full_text'])\n",
    "X_test_tfidf = transformer.transform(X_test_counts)\n",
    "X_test_nmf = nmf.transform(X_test_tfidf)\n",
    "y_test_pred = clf.predict(X_test_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11dbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get test parameters\n",
    "print('-'*20)\n",
    "print(\"Confusion matrix on test set is: \")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('-'*20)\n",
    "print('-'*20)\n",
    "print(\"Performance metrics on test set is: \")\n",
    "print (\"Precision is: \", metrics.precision_score(y_test, y_test_pred, average = 'macro'))\n",
    "print (\"Recall is: \", metrics.recall_score(y_test, y_test_pred, average = 'macro'))\n",
    "print (\"Accuracy is: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "print (\"F1 score is: \", metrics.f1_score(y_test, y_test_pred, average = 'macro'))\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## svm classification one vs one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fedb0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a85ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "\n",
    "## train the model\n",
    "\n",
    "## define model\n",
    "count_vectorizer = CountVectorizer(min_df=3, stop_words='english', analyzer=doc_tokens, max_df=0.7)\n",
    "transformer = TfidfTransformer()\n",
    "svd = TruncatedSVD(n_components=k, n_iter = 20, random_state=42) ## Multinomial NB can take only positive values\n",
    "clf = LinearSVC()\n",
    "ovo_classifier = OneVsOneClassifier(clf)\n",
    "\n",
    "## train model\n",
    "train['leaf_label_encode']= train['leaf_label'].map(map_class_to_val)\n",
    "y_train = train['leaf_label_encode']\n",
    "# print(y_train)\n",
    "X_train_counts = count_vectorizer.fit_transform(train['full_text'])\n",
    "X_train_tfidf = transformer.fit_transform(X_train_counts)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "model = ovo_classifier.fit(X_train_svd, y_train)\n",
    "\n",
    "## get train parameters\n",
    "\n",
    "## test model\n",
    "test['leaf_label_encode']= test['leaf_label'].map(map_class_to_val)\n",
    "y_test = test['leaf_label_encode']\n",
    "X_test_counts = count_vectorizer.transform(test['full_text'])\n",
    "X_test_tfidf = transformer.transform(X_test_counts)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "y_test_pred = ovo_classifier.predict(X_test_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8178b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get test parameters\n",
    "print('-'*20)\n",
    "print(\"Confusion matrix on test set is: \")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('-'*20)\n",
    "print('-'*20)\n",
    "print(\"Performance metrics on test set is: \")\n",
    "print (\"Precision is: \", metrics.precision_score(y_test, y_test_pred, average = 'macro'))\n",
    "print (\"Recall is: \", metrics.recall_score(y_test, y_test_pred, average = 'macro'))\n",
    "print (\"Accuracy is: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "print (\"F1 score is: \", metrics.f1_score(y_test, y_test_pred, average = 'macro'))\n",
    "print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## svm classification one vs rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "\n",
    "## train the model\n",
    "\n",
    "## define model\n",
    "count_vectorizer = CountVectorizer(min_df=3, stop_words='english', analyzer=doc_tokens, max_df=0.7)\n",
    "transformer = TfidfTransformer()\n",
    "svd = TruncatedSVD(n_components=k, n_iter = 20, random_state=42) ## Multinomial NB can take only positive values\n",
    "clf = LinearSVC(multi_class = 'ovr', class_weight = 'balanced')\n",
    "# clf = LinearSVC(multi_class = 'ovr')\n",
    "# ovr_classifier = OneVsRestClassifier(clf)\n",
    "\n",
    "## train model\n",
    "train['leaf_label_encode']= train['leaf_label'].map(map_class_to_val)\n",
    "y_train = train['leaf_label_encode']\n",
    "# print(y_train)\n",
    "X_train_counts = count_vectorizer.fit_transform(train['full_text'])\n",
    "X_train_tfidf = transformer.fit_transform(X_train_counts)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "model = clf.fit(X_train_svd, y_train)\n",
    "\n",
    "## get train parameters\n",
    "\n",
    "## test model\n",
    "test['leaf_label_encode']= test['leaf_label'].map(map_class_to_val)\n",
    "y_test = test['leaf_label_encode']\n",
    "X_test_counts = count_vectorizer.transform(test['full_text'])\n",
    "X_test_tfidf = transformer.transform(X_test_counts)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "y_test_pred = clf.predict(X_test_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get test parameters\n",
    "print('-'*20)\n",
    "print(\"Confusion matrix on test set is: \")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('-'*20)\n",
    "print('-'*20)\n",
    "print(\"Performance metrics on test set is: \")\n",
    "print (\"Precision is: \", precision_score(y_test, y_test_pred, average = 'macro'))\n",
    "print (\"Recall is: \", recall_score(y_test, y_test_pred, average = 'macro'))\n",
    "print (\"Accuracy is: \", accuracy_score(y_test, y_test_pred))\n",
    "print (\"F1 score is: \", f1_score(y_test, y_test_pred, average = 'macro'))\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f32632",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49a232",
   "metadata": {},
   "source": [
    "GLoVE embeddings - Global vectors for word representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d9616",
   "metadata": {},
   "source": [
    "#### Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff4c26",
   "metadata": {},
   "source": [
    "Q10 a. Why are GLoVE embeddings trained on the ratio of co-occurrence probabilities rather than\n",
    "the probabilities themselves?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47510ed",
   "metadata": {},
   "source": [
    "Ratio of the co-occurence probabilities helps determine the words in context which are relevant in distinguishing two different words and also helps determining which context word is more important for which key word. For example, let the context words be solid, gas, water and fashion being studied to understand the target words ice and steam. The probability of solid given ice (P(solid | ice)) and (P(solid| steam)) by itself does not provide much information but if we take the ratio (P(solid | ice) / (P(solid| steam)) given a corpus, we can see that solid is a relevant word in context of ice compared to steam and can help distinguish between ice and steam. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55086a3b",
   "metadata": {},
   "source": [
    "Q10 b. In the two sentences: James is running in the park. and James is running for the\n",
    "presidency., would GLoVE embeddings return the same vector for the word running in both\n",
    "cases? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04272d9",
   "metadata": {},
   "source": [
    "Since GLoVE is a global vector representation, after being trained on a large corpus using the co-occurence matrix of wordsfrom the corpus, the vector embeddings of the word remain unique. Hence, GLoVE will return same vector for the word \"running\" in the two sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546e338",
   "metadata": {},
   "source": [
    "Q10 c. What do you expect for the values of,\n",
    "||GLoVE[\"queen\"] - GLoVE[\"king\"] - GLoVE[\"wife\"] + GLoVE[\"husband\"]||2,\n",
    "||GLoVE[\"queen\"] - GLoVE[\"king\"]||2 and ||GLoVE[\"wife\"] - GLoVE[\"husband\"]||2 ?\n",
    "Compare these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ca84d",
   "metadata": {},
   "source": [
    "The distance between the embeddings of queen and king compared to the distance between the embeddings of wife and husband should be of similar value as they both have same semantic relationship. The difference between the queen and king and wife and husband should be close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849498e4",
   "metadata": {},
   "source": [
    "Q10 d. Given a word, would you rather stem or lemmatize the word before mapping it to its GLoVE\n",
    "embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5049711",
   "metadata": {},
   "source": [
    "Lemmatization would be preferred over stemming before mapping the word to its GLoVE embedding. This is becayse lemmatization with pos tagging is word base reduction on the basis of context of word. Also, lemmatization ensures the reduced word is actually an english word with close meaning to original word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3396d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "dimension_of_glove = 300\n",
    "with open(\"glove/glove.6B.300d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_king = ((embeddings_dict['king'] - embeddings_dict['queen'])**2)\n",
    "husband_wife = ((embeddings_dict['husband'] - embeddings_dict['wife'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(queen_king))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_king = np.linalg.norm(embeddings_dict['king'] - embeddings_dict['queen'])\n",
    "husband_wife = np.linalg.norm(embeddings_dict['husband'] - embeddings_dict['wife'])\n",
    "queen_king_husband_wife = np.linalg.norm(embeddings_dict['queen'] - embeddings_dict['king'] - \\\n",
    "                                         embeddings_dict['wife'] + embeddings_dict['husband'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f901a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.linalg.norm(embeddings_dict['husband'] - embeddings_dict['badminton'])\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (embeddings_dict['king'] - embeddings_dict['queen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e113a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1693a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(queen_king)\n",
    "print(husband_wife)\n",
    "print(queen_king_husband_wife)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7dcc46",
   "metadata": {},
   "source": [
    "#### Question 11\n",
    "\n",
    "Train a binary classification model using GLoVE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa9a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering using Glove word embeddings\n",
    "\n",
    "def get_document_vector (doc_keywords:list, embeddings_dict: dict, embed_size = 300 ):\n",
    "    '''\n",
    "    From the list of keywords representing the document, get a document embedding\n",
    "    '''\n",
    "    representation = np.zeros(embed_size)\n",
    "    count = 0\n",
    "    for word in doc_keywords:\n",
    "        try:\n",
    "            embed = embeddings_dict[word]\n",
    "            count = count+1\n",
    "            representation = np.add(representation, embed)    \n",
    "        except:\n",
    "            count = count\n",
    "    return (representation / count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(doc: str):\n",
    "    '''\n",
    "    Clean full text without any stemming or lemmatization\n",
    "    '''\n",
    "    doc = clean(doc)\n",
    "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    lower_txt = [token.lower() for token in tokens]\n",
    "    remove_words = [token for token in lower_txt if (not token.isdigit())\\\n",
    "                     and (token not in combined_stopwords) and (len(token)>1)]\n",
    "    return (word for word in remove_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_feature_mapping (data: pd.DataFrame(), embeddings_dict: dict, embed_size = 300):\n",
    "    feature_map = np.zeros(embed_size)\n",
    "    for index, row in data.iterrows():\n",
    "#         keywords = row['keywords']\n",
    "#         print(keywords)\n",
    "        keywords = get_tokens(row['full_text'])\n",
    "        embed = get_document_vector(keywords, embeddings_dict, embed_size)\n",
    "        feature_map = np.vstack((feature_map,embed))\n",
    "    feature_map = feature_map[1:,:]\n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ab553",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty = 'none', max_iter=10000, random_state=42)\n",
    "# clf = SVC(kernel='linear', C=10, random_state=42)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "## train model\n",
    "y_train = label_encoder.fit_transform(train['root_label'])\n",
    "# print(y_train)\n",
    "X_train = data_to_feature_mapping(train, embeddings_dict, 300)\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "## get train parameters\n",
    "\n",
    "## test model\n",
    "y_test = label_encoder.transform(test['root_label'])\n",
    "X_test = data_to_feature_mapping(test, embeddings_dict, 300)\n",
    "y_test_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b01571",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get test parameters\n",
    "print('-'*20)\n",
    "print(\"Confusion matrix on test set is: \")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('-'*20)\n",
    "print('-'*20)\n",
    "print(\"Performance metrics on test set is: \")\n",
    "print (\"Precision is: \", metrics.precision_score(y_test, y_test_pred))\n",
    "print (\"Recall is: \", metrics.recall_score(y_test, y_test_pred))\n",
    "print (\"Accuracy is: \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "print (\"F1 score is: \", metrics.f1_score(y_test, y_test_pred))\n",
    "print('-'*20)\n",
    "\n",
    "print('-'*20)\n",
    "print(\"ROC curve on test set is: \")\n",
    "y_test_pred_proba = clf.predict_proba(X_test)[::,1]\n",
    "# y_test_pred_proba = clf.decision_function(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_test_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177f9f2",
   "metadata": {},
   "source": [
    "#### Question 12\n",
    "\n",
    "Trend between embedding size and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98447ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = [50,100,200,300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty = 'none',max_iter=10000, random_state=42)\n",
    "# clf = SVC(kernel='linear', C=10, random_state=42)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "## label encoding\n",
    "y_train = label_encoder.fit_transform(train['root_label'])\n",
    "y_test = label_encoder.transform(test['root_label'])\n",
    "\n",
    "## report test accuracy on different embedding size\n",
    "accuracy = []\n",
    "accuracy_train = []\n",
    "for size in embed_size:\n",
    "    \n",
    "    embeddings_dict = {}\n",
    "    with open(\"glove/glove.6B.\"+ str(size)+\"d.txt\", 'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "    \n",
    "    X_train = data_to_feature_mapping(train, embeddings_dict, size)\n",
    "    model = clf.fit(X_train, y_train)\n",
    "\n",
    "    X_test = data_to_feature_mapping(test,embeddings_dict, size)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    accuracy.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "    accuracy_train.append(metrics.accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaebe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dce88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6918a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the explained variance ratio across number of components\n",
    "plt.plot(embed_size, accuracy)\n",
    "plt.xlabel('embed_size')\n",
    "plt.ylabel('test_accuracy')\n",
    "plt.title('GLoVE embedding')\n",
    "plt.savefig('glove_embed.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d096d",
   "metadata": {},
   "source": [
    "#### Question 13\n",
    "\n",
    "Visualize using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 300\n",
    "embeddings_dict = {}\n",
    "with open(\"glove/glove.6B.\"+ str(size)+\"d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "\n",
    "X_train = data_to_feature_mapping(train, embeddings_dict, size)\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "scaled_data = StandardScaler().fit_transform(X_train)\n",
    "embedding = reducer.fit_transform(scaled_data)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98092c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=[sns.color_palette()[x] for x in train.root_label.map({\"sports\":0, \"climate\":1})])\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of the Training dataset', fontsize=24)\n",
    "plt.savefig(\"umap_train.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_data = np.random.rand(1657,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942364c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "scaled_data_rand = StandardScaler().fit_transform(rand_data)\n",
    "embedding_rand = reducer.fit_transform(scaled_data_rand)\n",
    "embedding_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e93b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    embedding_rand[:, 0],\n",
    "    embedding_rand[:, 1],\n",
    "    c=[sns.color_palette()[x] for x in train.root_label.map({\"sports\":0, \"climate\":1})])\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of the random dataset', fontsize=24)\n",
    "plt.savefig(\"umap_random.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e9288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a73b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9f2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
